####################################################################
# Sample Logstash v1.5.x Configuration for RedHat JBOSS EAP App Server 6.2
#
# Web: http://www.jboss.org/products/eap/overview/
# Community: http://www.jboss.org/products/eap/community/
# Docs: http://www.jboss.org/products/eap/resources/
# Log Info: https://access.redhat.com/documentation/en-US/JBoss_Enterprise_Application_Platform/6.2/html/Administration_and_Configuration_Guide/chap-The_Logging_Subsystem.html
#
####################################################################
# v1.0 Doug McClure 9/23/15 RedHat JBOSS EAP App Server 6.2 - server.log
#
####################################################################

input {

#############################################################################################
#RedHat JBOSS EAP App Server 6.2
#############################################################################################

#file inputs used as I was provided sample logfiles. In a live streaming environment other inputs like TCP would be used here.

#server.log, server.log.DATE
file {
		path => "/opt/scala/driver/Logstash/REDHAT-JBOSS-EAP/redhat_jboss_eap_logs/foobar1/server*"
		#this forces the entire logfile to be read from beginning. Creates tracking state file in $HOME directory as .sincedb.... (delete to reprocess log)
		start_position => "beginning"
		exclude => "*gc*"
		type => "REDHAT-JBOSS-EAP"
		tags => ["server_log"]
	}
	
	
##########################################################################

} #end input

##########################################################################

filter {

#common stuff for all logs

#copy orig filepath to new fields

	mutate {
		add_field => { "origFilePath" => "%{path}" }
		add_tag => [ "origFilePathCreated" ]
	} #end mutate

#parse hostname and logfile name from new filepath field and create new hostname and logfile fields
#add add' patterns for other directories as needed

	grok {
		match => {"origFilePath" => "redhat_jboss_eap_logs/%{DATA:hostname}/%{GREEDYDATA:logfile}"}
		add_tag => [ "hostnameLogfileCreated" ]
	} #end grok
	
############################################################
# RedHat JBOSS EAP App Server 6.2
############################################################

if [type] == "REDHAT-JBOSS-EAP" and "hostnameLogfileCreated" in [tags] {

	if "server_log" in [tags] {
		
		#this fixes multiline log messages like stack traces which were found in log samples
		
		multiline {
			pattern => "^%{JBOSSEAPTIME}"
			patterns_dir => ["/opt/scala/driver/Logstash/logstash-1.5.3/patterns"]
			negate => "true"
			what => "previous"
		} #end multi
		
		#extract useful fields based on patterns seen in sample logs provided
		
		grok {
			match => {"message" => "%{JBOSSEAP1}"}
			match => {"message" => "%{JBOSSEAP2}"}
			match => {"message" => "%{JBOSSEAP3}"}
			patterns_dir => ["/opt/scala/driver/Logstash/logstash-1.5.3/patterns"]
			add_tag => [ "REDHAT-JBOSS-EAP-server_log-Grokked" ]
		} #end grok
		
		#normalize date format to ISO8601
		#05:53:59,794
		#this log type sample didn't have a full timestamp with date so everything here is using local date with correct time.  In real deployment this would synch up with live data so date is accurate.
		
		date {
			match => [ "origTimestamp", "HH:mm:ss,SSS" ]
			target => "@timestamp"
			add_tag => [ "timestamp-fixed" ]
		} #end date
		
		#set the host/path value for the LA datasource.  This is set for consolidation of all logs to functional datasources in LA.
		
		mutate {
			#replace => [ "host", "%{hostname}", "path", "%{type}-server_log" ]
			replace => [ "host", "server_log", "path", "%{type}" ]
			add_tag => [ "REDHAT-JBOSS-EAP-Final" ]
		} #end mutate
		
	} #end server_log conditional
	
} #end REDHAT-JBOSS-EAP conditional


##########################################################################

} #end filter

##########################################################################

output {

if "REDHAT-JBOSS-EAP-Final" in [tags] {
	
	scala {
		scala_url => "https://10.0.0.1:9987/Unity/DataCollector"
		scala_user => "unityadmin"
		scala_password => "unityadmin"
		scala_keystore_path => ""
		batch_size => 500000
		idle_flush_time => 5
		sequential_flush => true
		num_concurrent_writers => 20
		use_structured_api => false
		disk_cache_path => "/opt/scala/driver/Logstash/cache-dir"
		scala_fields =>
		  {
			"server_log@REDHAT-JBOSS-EAP" => "@timestamp,hostname,logfile,loglevel,class,thread,messageID,message"
		  }
		#the default timestamp format for string field @timestamp - may need to tweak to fit based on LA+logstash vesion you're using
		date_format_string => "yyyy-MM-dd'T'HH:mm:ssX"
		log_file => "/opt/scala/driver/Logstash/logs/scala_logstash.log"
		log_level => "info"
	} #end LA output
	
} #end LA output conditional	

###### DEBUGGING ###########

# show rubydebug in the console

stdout {
    codec => rubydebug
    } #end stdout
	
if "_grokparsefailure" in [tags] {
	file {
		message_format => "%{message}"
		path => "/opt/scala/driver/Logstash/logs/REDHAT-JBOSS-EAP/%{type}-%{hostname}-%{logfile}-grok-debug.log"
	} # end file 
} #end conditional

} #end output